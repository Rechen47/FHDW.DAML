{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427529a5",
   "metadata": {},
   "source": [
    "### Random Forrests auf DMC 2010 Daten\n",
    "\n",
    "#### Versionsgeschichte\n",
    "\n",
    "- 1.0 05.10.2022 Willi Hahn Initialversion\n",
    "- 2.0 10.05.2023 Willi Hahn Anapssung für DAML Kurs SS2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2253dd",
   "metadata": {},
   "source": [
    "#### Einmalige Installation notwendiger Pakete wird in VL 3 beschrieben.\n",
    "#### Verwendet werden hier die Bibliotheken pandas, numpy, matplotlib, seaborn, sklearn, imblearn\n",
    "##### einmalig installieren, wenn ModuleNotFound error auftritt\n",
    "##### dann Zelle als Zelltyp Code umwandeln und ausführen\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install imbalanced-learn  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f965de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notwendige Bibliotheken importieren und Verbesserung der Laufzeitkonfiguration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "_ = pd.set_option('display.max_columns', None) # damit mehr als 20 Spalten angezeigt werden.\n",
    "#                                                    _ =  damit Objektausgabe unterdrückt wird.\n",
    "pd.set_option('display.min_rows', 15) # damit nicht nur 10 Zeilen mit  ... dazwischen ausgegeben werden\n",
    "pd.set_option('display.max_rows', 500) # damit nicht nur 10 Zeilen mit  ... dazwischen ausgegeben werden\n",
    "import seaborn as sns #importing Seaborn's for plots\n",
    "from sklearn import metrics as met \n",
    "import matplotlib.pyplot as plt #Plot Bibliothek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer as timer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56688dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path = 'c:/myBox/Projekte/FHDW/Kurs DAML/python/dmc2010_train.txt' # für lokale Dateien\n",
    "path = 'https://github.com/Rechen47/FHDW.DAML/raw/main/dmc2010_train.txt'\n",
    "\n",
    "# Datentypen benennen\n",
    "num_cols = ['numberitems', 'weight', 'remi', 'cancel', 'used', 'w0', 'w1',\n",
    "                'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10']\n",
    "date_cols = ['date', 'datecreated', 'deliverydatepromised', 'deliverydatereal']\n",
    "cat_cols = ['delivpostcode', 'advertisingdatacode', 'salutation', 'title',\n",
    "                'domain', 'newsletter', 'model', 'paymenttype', 'deliverytype',\n",
    "                'invoicepostcode', 'voucher', 'case', 'gift', 'entry', 'points',\n",
    "                'shippingcosts']\n",
    "target_col = 'target90'\n",
    "\n",
    "df = pd.read_csv(path, sep=';', index_col='customernumber', parse_dates=date_cols, low_memory=False)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenvorbereitung : Spalten wegen zu wenig Information entfernen\n",
    "df.drop(columns=['delivpostcode'], inplace=True, axis=1)\n",
    "df.drop(columns=['points'], inplace=True, axis=1)\n",
    "df.drop(columns=['title'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Alternative für delivpostcode\n",
    "#df['delivpostcode'] = df['delivpostcode'].replace(['Nl'],-1)\n",
    "#df['delivpostcode'] = df['delivpostcode'].replace(['EN'],-2)\n",
    "#df['delivpostcode'] = df['delivpostcode'].fillna(-3)\n",
    "##\n",
    "\n",
    "\n",
    "# Datenvorbereitung : Encoding der string variablen advertisingdatacode\n",
    "# Bitte die nicht benutzte Variante auskommentieren!\n",
    "#\n",
    "# Methode 1 Codieren als aufsteigende Ganzzahl\n",
    "df['advertisingdatacode']= df['advertisingdatacode'].astype('category').cat.codes\n",
    "# Methode 2 Codieren mit one hot encoding\n",
    "#df['advertisingdatacode']=df['advertisingdatacode'].astype('string')\n",
    "# ersetze alle advertisingdatacode, die Train- oder Eval-Daten fehlen durch AA\n",
    "#df['advertisingdatacode']=df['advertisingdatacode'].replace(['AA','AC','AJ','AS','AU','AS','BH','BG','BN','BU','BW'], 'AA') \n",
    "##print (df['advertisingdatacode'].value_counts(ascending=True) )\n",
    "#df = pd.get_dummies(df, columns = ['advertisingdatacode'], prefix='adcode', prefix_sep='_', drop_first=False)\n",
    "#df.info()\n",
    "\n",
    "# Datenvorbereitung : Üngültige Werte behandeln\n",
    "# Folgende Korrektur von invoicepostcode nur notwendig für die Evaluaierungdaten\n",
    "# to_numeric wandelt ?? in NaN, der dann durch den Median ersetzt wird\n",
    "df['invoicepostcode'] = pd.to_numeric(df['invoicepostcode'], errors='coerce').round()\n",
    "#df['invoicepostcode'].fillna(df['invoicepostcode'].median(), inplace=True)\n",
    "df['invoicepostcode']=df['invoicepostcode'].astype(np.int64)\n",
    "\n",
    "#deliverydatereal und 0000-00-00 ca 17% in Trainings- und Evaluierungsdaten\n",
    "df['deliverydatereal'] = df['deliverydatereal'].astype('string')\n",
    "df.replace({'deliverydatereal': {'0000-00-00': df['date'].astype('string')}}, inplace=True)\n",
    "df['deliverydatereal'] = pd.to_datetime(df['deliverydatereal'], infer_datetime_format=True)\n",
    "#df['deliverydatereal'].info()\n",
    "#print (df['deliverydatereal'].value_counts().sort_index() )\n",
    "\n",
    "#df[(df['deliverydatepromised'] > '2013-01-01')]\n",
    "df['deliverydatepromised']= df['deliverydatepromised'].replace('4746', '2009', regex=True) \n",
    "# jahr 4746 wird durch , errors=\"coerce\" abgedeckt, weil dadurch der out of bounds error ignoriert wird\n",
    "df['deliverydatepromised'] = pd.to_datetime(df['deliverydatepromised'], infer_datetime_format=True)\n",
    "#df.info()\n",
    "\n",
    "\n",
    "# Datenvorbereitung : Datumsfelder als Anzahl Tage auf Bezugsdatum umwandeln\n",
    "df['DaysToFirstorder'] = (df['date'] - df['datecreated']).dt.days\n",
    "df['DaysAccountAge'] = (pd.to_datetime(\"2009-05-01\") - df['datecreated']).dt.days # fixes Bezugsdatum\n",
    "\n",
    "#df['deliverydatepromised'] = df['deliverydatepromised'].fillna(df['date'], inplace=True )\n",
    "#df['deliverydatereal'] = df['deliverydatereal'].fillna(df['date'], inplace=True )\n",
    "df[\"deliverydatepromised\"] = pd.to_datetime(df[\"deliverydatepromised\"], errors=\"coerce\")\n",
    "df[\"deliverydatereal\"] = pd.to_datetime(df[\"deliverydatereal\"], errors=\"coerce\")\n",
    "df['DaysDeliveryPromised'] = ((df['deliverydatereal'] - df['deliverydatepromised']).dt.days).astype('Int64')\n",
    "#df['DaysToFirstorder'].unique()\n",
    "#df['DaysAccountAge'].unique()\n",
    "#df['DaysDeliveryPromised'].unique()\n",
    "df.drop(date_cols, axis=1, inplace=True)\n",
    "#df[['date', 'DaysToFirstorder', 'datecreated', 'DaysAccountAge','deliverydatepromised', 'deliverydatereal','DaysDeliveryPromised']]\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff972d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings- und Testdaten aufteilen\n",
    "\n",
    "TESTANTEIL = 0.25 # Split der Test- und Trainingsdaten\n",
    "\n",
    "\n",
    "#df.info()\n",
    "\n",
    "# Trennung von unabhängigen Variablen und abhängiger Zielvariable\n",
    "y = df['target90']\n",
    "x = df.drop(['target90'], axis = 1)\n",
    "#x.head().T\n",
    "#y.head().T\n",
    "classratio = y.sum() / y.count()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TESTANTEIL, random_state=42)\n",
    "\n",
    "# und prüfen durch ansehen\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)\n",
    "#x_train.info()\n",
    "#y_train.info()\n",
    "#x_train.head().T\n",
    "#y_train.head().T\n",
    "print (pd.DataFrame(y_train).value_counts())\n",
    "print (pd.DataFrame(y_test).value_counts())\n",
    "\n",
    "print('\\nKlassenverhältnis target90 TRAIN: %.3f' % (y_train.sum() / y_train.count()),\\\n",
    "      '\\nKlassenverhältnis target90 TEST:  %.3f' % (y_test.sum() / y_test.count()),\\\n",
    "      '\\nKlassenverhältnis target90 Gesamt:  %.3f' % classratio)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9100fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datenvorbereitung : Variablen skalieren\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#\n",
    "SCALER = StandardScaler()\n",
    "#SCALER = MinMaxScaler()\n",
    "\n",
    "x_train = SCALER.fit_transform(x_train)\n",
    "x_test = SCALER.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c00771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancierung zwischen Mehr- und Minderheitsklassen\n",
    "# Nicht notwendig für Random Forrests\n",
    "\n",
    "# Variante RandomUnderSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#under_sample = RandomUnderSampler(random_state=42)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "# Variante RandomOverSampler\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#over_sample = RandomOverSampler(sampling_strategy='auto')\n",
    "#x_train, y_train = over_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "## Variante SMOTE\n",
    "# führt zu TypeError: cannot safely cast non-equivalent float64 to int64 wegen Int64\n",
    "#   DaysDeliveryPromised cast auf INT führt aber zu TP=FP=0 !\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42, sampling_strategy='minority', k_neighbors=3)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "# die nächsten Varianten nach https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
    "# Variante NearMiss\n",
    "#from imblearn.under_sampling import NearMiss\n",
    "#under_sample = NearMiss(version=3, n_neighbors=3)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "# Variante EditedNearestNeighbours\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "under_sample = EditedNearestNeighbours(n_neighbors=3)\n",
    "x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "# Variante NeighbourhoodCleaningRule\n",
    "#from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "#under_sample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.8)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7796dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelltraining\n",
    "# Random Forest berechnen\n",
    "# \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Decision tree parameter see https://python.plainenglish.io/decision-tree-parameters-explanations-tuning-a2b0749976e5\n",
    "N_ESTIMATORS = 40   # Anzahl Bäume\n",
    "N_JOBS = -1   #\n",
    "CRITERION = 'gini'   # “gini”,”entropy”}, default = “gini”\n",
    "MAX_DEPTH = 50       # int, default = None\n",
    "MIN_IMPURITY_SPLIT = None  #\n",
    "MIN_SAMPLES_SPLIT = 2   # int or float, default = 2\n",
    "MIN_SAMPLES_LEAF = 1    # int or float, default = 1\n",
    "MIN_WEIGHT_FRACTION_LEAF = 0  #  float, default = 0\n",
    "OOB_SCORE=False   #\n",
    "RANDOM_STATE = 42   # int, RandomState instance or None, default = None\n",
    "MAX_LEAF_NODES = None   # int, default = None\n",
    "MIN_IMPURITY_INCREASE = 0.0 # float, default = 0.0\n",
    "CLASS_WEIGHT = None # dict, list of dict or “balanced”, default = None\n",
    "VERBOSE = 0\n",
    "WARM_START=False  #\n",
    "\n",
    "\n",
    "t0 = timer()\n",
    "classifier = RandomForestClassifier(n_estimators=N_ESTIMATORS, criterion=CRITERION, \n",
    "                                   max_depth=MAX_DEPTH, min_samples_split=MIN_SAMPLES_SPLIT, min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                                   # min_impurity_split=MIN_IMPURITY_SPLIT,\n",
    "                                   min_weight_fraction_leaf=MIN_WEIGHT_FRACTION_LEAF, random_state=RANDOM_STATE,\n",
    "                                   max_leaf_nodes=MAX_LEAF_NODES, min_impurity_decrease=MIN_IMPURITY_INCREASE,\n",
    "                                   n_jobs=N_JOBS, oob_score=OOB_SCORE,\n",
    "                                   class_weight=CLASS_WEIGHT, verbose=VERBOSE, warm_start=WARM_START)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "t1 = timer()\n",
    "print ('Laufzeit Vorhersage = ', round(t1 - t0, 0), ' sec')\n",
    "#print (pd.DataFrame(y_pred).value_counts())\n",
    "\n",
    "\n",
    "print (\"\\nFeature Importance\")\n",
    "feature_names = list(pd.DataFrame(x_train).columns)\n",
    "feature_imp = pd.Series(classifier.feature_importances_,index=feature_names).sort_values(ascending=False)\n",
    "print (feature_imp)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrheitsmatrix und Maßzahlen der Vorhersage untersuchen\n",
    "\n",
    "# Adding classes names for better interpretation\n",
    "classes_names = ['Kein Kauf\\n(negativ)','Kauf   \\n(positiv)']\n",
    "cm = met.confusion_matrix(y_test, y_pred);\n",
    "cmdf = pd.DataFrame(cm, columns=classes_names, index = classes_names); # data frame bilden\n",
    "tn, fp, fn, tp = cm.ravel();\n",
    "\n",
    "# Seaborn's heatmap to visualize the confusion matrix\n",
    "sns.heatmap(data=cmdf, cmap='gray_r', vmin=0, vmax=0,\n",
    "                 annot=[[f\"TN={tn:.0f}\", f\"FP={fp:.0f}\"], [f\"FN={fn:.0f}\", f\"TP={tp:.0f}\"]],\n",
    "                 linewidths=0.5, linecolor='k',  # draw black grid lines\n",
    "                 clip_on=False,                  # inhibits clipping of right and lower square lines\n",
    "                 fmt='', annot_kws={'fontsize': 16}, cbar=False, square=True);\n",
    "\n",
    "plt.title(\"Wahrheitsmatrix Testdaten (Split=\"+str(TESTANTEIL)+\")\");\n",
    "plt.ylabel('Aktuelle Testdaten');\n",
    "plt.xlabel('Vorhersagen');\n",
    "\n",
    "print(\"Testdatenanteil= \"+str(TESTANTEIL))\n",
    "print (\"\\nTP:TN:FP:FN = \" + str (tp) +\":\" + str (tn) +\":\" + str (fp) +\":\" + str (fn) )\n",
    "print (\"Genauigkeit = {:.2f}\".format(met.accuracy_score(y_test, y_pred)))\n",
    "print (\"Recall = {:.2f}\".format(met.recall_score(y_test, y_pred, average='binary')))\n",
    "print (\"Präzision = {:.2f}\".format(met.precision_score(y_test, y_pred, average='binary')))\n",
    "print (\"F1 Wert = {:.2f}\".format(met.f1_score(y_test, y_pred, average='binary')))\n",
    "print (\"Speziftät = {:.2f}\".format(tn /(tn+fp)))\n",
    "print (\"TPR = {:.2f}\".format(tp /(tp+fp)))\n",
    "print (\"FPR = {:.2f}\".format(fp /(tn+fn)))\n",
    "print (\"TNR = {:.2f}\".format(tn /(tn+fn)))\n",
    "print (\"FNR = {:.2f}\".format(fn /(tp+fp)))\n",
    "\n",
    "print (\"\\nUmsatzsteigerung für die Testdaten = {:.2f}\".format(1.5*tn - 5.0*fn)+\" €\")\n",
    "print (\"Umsatzsteigerung für hochgerechnet für alle Testdaten = {:.2f}\".format((1.5*tn - 5.0*fn) * (1/TESTANTEIL) ) +\" €\")\n",
    "print (\"Umsatzsteigerung für baseline (Gutschein an Alle) = {:.2f}\".format((df.shape[0] * (1-classratio) * 1.5) -\\\n",
    "                                                                           (df.shape[0] * classratio * 5)) +\" €\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
