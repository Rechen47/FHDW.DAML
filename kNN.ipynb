{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd34364",
   "metadata": {},
   "source": [
    "### k-Nächste Nachbarn Verfahren auf DMC 2010 Daten\n",
    "\n",
    "#### Versionsgeschichte\n",
    "- 1.0 05.10.2022 Willi Hahn Initialversion\n",
    "- 2.0 07.05.2023 Willi Hahn Anapssung für DAML Kurs SS2023 \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3183392e",
   "metadata": {},
   "source": [
    "##### notwendige Bibliotheken installieren \n",
    "##### einmalig installieren, wenn ModuleNotFound error auftritt\n",
    "##### dann Zelle als Zelltyp Code umwandeln und ausführen\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install imbalanced-learn  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6dfe86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# notwendige Bibliotheken importieren und Verbesserung der Laufzeitkonfiguration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "_ = pd.set_option('display.max_columns', None) # damit mehr als 20 Spalten angezeigt werden.\n",
    "#                                                    _ =  damit Objektausgabe unterdrückt wird.\n",
    "pd.set_option('display.min_rows', 15) # damit nicht nur 10 Zeilen mit  ... dazwischen ausgegeben werden\n",
    "pd.set_option('display.max_rows', 500) # damit nicht nur 10 Zeilen mit  ... dazwischen ausgegeben werden\n",
    "import seaborn as sns #importing Seaborn's for plots\n",
    "from sklearn import metrics as met \n",
    "import matplotlib.pyplot as plt #Plot Bibliothek\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962e8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daten für Training einLesen \n",
    "\n",
    "#path = 'c:/myBox/Projekte/FHDW/Kurs DAML/python/dmc2010_train.txt' # für lokale Dateien\n",
    "path = 'https://raw.githubusercontent.com/FHDW-DAML/22Q4/main/dmc2010_train.txt'  # für Colab\n",
    "\n",
    "# Datentypen benennen\n",
    "num_cols = ['numberitems', 'weight', 'remi', 'cancel', 'used', 'w0', 'w1',\n",
    "                'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10']\n",
    "date_cols = ['date', 'datecreated', 'deliverydatepromised', 'deliverydatereal']\n",
    "cat_cols = ['delivpostcode', 'advertisingdatacode', 'salutation', 'title',\n",
    "                'domain', 'newsletter', 'model', 'paymenttype', 'deliverytype',\n",
    "                'invoicepostcode', 'voucher', 'case', 'gift', 'entry', 'points',\n",
    "                'shippingcosts']\n",
    "target_col = 'target90'\n",
    "\n",
    "df = pd.read_csv(path, sep=';', index_col='customernumber', parse_dates=date_cols, low_memory=False)\n",
    "#df.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7771f5c",
   "metadata": {},
   "source": [
    "# Datenvorbereitung für den ersten Durchstich zum ersten Modell : \n",
    "#     Variablen löschen, die zu Fehlern bei der Modellbildung führen würden\n",
    "\n",
    "print (\"Alle Spalten mit Nulls Werte im data frame löschen wir, damit das k-nächste Nachbarn Verfahren arbeiten kann.\")\n",
    "df.drop(columns=['advertisingdatacode', 'delivpostcode'], inplace=True, axis=1)\n",
    "print (\"Alle Datumsfelder im data frame löschen wir, damit das k-nächste Nachbarn Verfahren arbeiten kann.\")\n",
    "df.drop(columns=date_cols, inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenvorbereitung  \n",
    "# Spalten wegen zu wenig Information entfernen\n",
    "#df.drop(columns=['delivpostcode'], inplace=True, axis=1)\n",
    "df.drop(columns=['points'], inplace=True, axis=1)\n",
    "df.drop(columns=['title'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Alternative für delivpostcode: statt Entfernen, fehlende Daten mit einer Konstanten füllen.\n",
    "df['delivpostcode'] = df['delivpostcode'].fillna(-3)\n",
    "# dann auch fehlerhafte Daten korrigieren\n",
    "df['delivpostcode'] = df['delivpostcode'].replace(['Nl'],-1)\n",
    "df['delivpostcode'] = df['delivpostcode'].replace(['EN'],-2)\n",
    "\n",
    "# Encoding der string variablen advertisingdatacode\n",
    "# Bitte die nicht benutzte Variante auskommentieren!\n",
    "#\n",
    "# Methode 1 Codieren als aufsteigende Ganzzahl\n",
    "#df['advertisingdatacode']= df['advertisingdatacode'].astype('category').cat.codes\n",
    "# Methode 2 Codieren mit one hot encoding\n",
    "df['advertisingdatacode']=df['advertisingdatacode'].astype('string')\n",
    "# ersetze alle advertisingdatacode, die Train- oder Eval-Daten fehlen durch AA\n",
    "df['advertisingdatacode']=df['advertisingdatacode'].replace(['AA','AC','AJ','AS','AU','AS','BH','BG','BN','BU','BW'], 'AA') \n",
    "#print (df['advertisingdatacode'].value_counts(ascending=True) )\n",
    "df = pd.get_dummies(df, columns = ['advertisingdatacode'], prefix='adcode', prefix_sep='_', drop_first=False)\n",
    "#df.info()\n",
    "\n",
    "# Üngültige Werte behandeln\n",
    "# Folgende Korrektur von invoicepostcode nur notwendig für die Evaluaierungdaten\n",
    "# to_numeric wandelt ?? in NaN, der dann durch den median ersetzt wird\n",
    "df['invoicepostcode'] = pd.to_numeric(df['invoicepostcode'], errors='coerce').round()\n",
    "df['invoicepostcode'].fillna(df['invoicepostcode'].median(), inplace=True)\n",
    "df['invoicepostcode']=df['invoicepostcode'].astype(np.int64)\n",
    "\n",
    "#deliverydatereal und 0000-00-00 ca 17% in Trainings- und Evaluierungsdaten\n",
    "df['deliverydatereal'] = df['deliverydatereal'].astype('string')\n",
    "df.replace({'deliverydatereal': {'0000-00-00': df['date'].astype('string')}}, inplace=True)\n",
    "df['deliverydatereal'] = pd.to_datetime(df['deliverydatereal'], infer_datetime_format=True)\n",
    "#df['deliverydatereal'].info()\n",
    "#print (df['deliverydatereal'].value_counts().sort_index() )\n",
    "\n",
    "#df[(df['deliverydatepromised'] > '2013-01-01')]\n",
    "df['deliverydatepromised']= df['deliverydatepromised'].replace('4746', '2009', regex=True) \n",
    "# jahr 4746 wird durch , errors=\"coerce\" abgedeckt, weil dadurch der out of bounds error ignoriert wird\n",
    "df['deliverydatepromised'] = pd.to_datetime(df['deliverydatepromised'], infer_datetime_format=True)\n",
    "#df.info()\n",
    "\n",
    "\n",
    "# Datumsfelder als Anzahl Tage auf Bezugsdatum umwandeln\n",
    "df['DaysToFirstorder'] = (df['date'] - df['datecreated']).dt.days\n",
    "df['DaysAccountAge'] = (pd.to_datetime(\"2009-05-01\") - df['datecreated']).dt.days # fixes Datum\n",
    "\n",
    "#df['deliverydatepromised'] = df['deliverydatepromised'].fillna(df['date'], inplace=True )\n",
    "#df['deliverydatereal'] = df['deliverydatereal'].fillna(df['date'], inplace=True )\n",
    "df[\"deliverydatepromised\"] = pd.to_datetime(df[\"deliverydatepromised\"], errors=\"coerce\")\n",
    "df[\"deliverydatereal\"] = pd.to_datetime(df[\"deliverydatereal\"], errors=\"coerce\")\n",
    "df['DaysDeliveryPromised'] = ((df['deliverydatereal'] - df['deliverydatepromised']).dt.days).astype('int64')\n",
    "#df['DaysToFirstorder'].unique()\n",
    "#df['DaysAccountAge'].unique()\n",
    "#df['DaysDeliveryPromised'].unique()\n",
    "print (df[['date', 'DaysToFirstorder', 'datecreated', 'DaysAccountAge','deliverydatepromised', 'deliverydatereal','DaysDeliveryPromised']])\n",
    "df.drop(date_cols, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1e88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trainings- und Testdaten aufteilen\n",
    "\n",
    "TESTANTEIL=0.25\n",
    "\n",
    "#df.info()\n",
    "\n",
    "# Trennung von unabhängigen Variablen und abhängiger Zielvariable\n",
    "y = df['target90']\n",
    "x = df.drop(['target90'], axis = 1)\n",
    "#x.head().T\n",
    "#y.head().T\n",
    "classratio = y.sum() / y.count()\n",
    "x_columns = x.columns\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TESTANTEIL, random_state=42)\n",
    "\n",
    "# und prüfen durch ansehen\n",
    "#print (x_train.shape)\n",
    "#print (y_train.shape)\n",
    "#print (x_test.shape)\n",
    "#print (y_test.shape)\n",
    "#x_test.info()\n",
    "#x_train.head().T\n",
    "#y_train.head().T\n",
    "\n",
    "print('\\nKlassenverhältnis target90 TRAIN: %.3f' % (y_train.sum() / y_train.count()),\\\n",
    "      '\\nKlassenverhältnis target90 TEST:  %.3f' % (y_test.sum() / y_test.count()),\\\n",
    "      '\\nKlassenverhältnis target90 Gesamt:  %.3f' % classratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944caa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datenvorbereitung : Variablen skalieren\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#\n",
    "SCALER = StandardScaler()\n",
    "#SCALER = MinMaxScaler()\n",
    "#\n",
    "x_train = SCALER.fit_transform(x_train)\n",
    "x_test = SCALER.transform(x_test)\n",
    "\n",
    "# Retain feature names after SCALER reduces to numpy series instead of pandas data frame\n",
    "x_train = pd.DataFrame(x_train, columns = x_columns)\n",
    "x_test = pd.DataFrame(x_test, columns = x_columns)\n",
    "#print (x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancierung zwischen Mehr- und Minderheitsklassen\n",
    "# Kommentieren Sie eine Variante durch Entfernen des Kommentarzeichen aus.\n",
    "# Fügen Sie das Kommentarzeichen für Ihr nächstes Experiment wieder ein.\n",
    "\n",
    "# Variante RandomUnderSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#under_sample = RandomUnderSampler(random_state=42)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "# Variante RandomOverSampler\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#over_sample = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "#x_train, y_train = over_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "# Variante SMOTE\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state=42, sampling_strategy='minority', k_neighbors=3)\n",
    "#x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "# die nächsten Varianten nach https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
    "# Variante NearMiss\n",
    "#from imblearn.under_sampling import NearMiss\n",
    "#under_sample = NearMiss(version=3, n_neighbors=3)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "# Variante EditedNearestNeighbours\n",
    "#from imblearn.under_sampling import EditedNearestNeighbours\n",
    "#under_sample = EditedNearestNeighbours(n_neighbors=3)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "# Variante NeighbourhoodCleaningRule\n",
    "#from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "#under_sample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.8)\n",
    "#x_train, y_train = under_sample.fit_resample(x_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada81c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Modelltraining\n",
    "#\n",
    "# Parameter nach https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "K_PARAM = 17 # Anzahl Nachbarn für die k-NN Vorhersage\n",
    "METRIC = 'euclidean' # cosine oder euclidean Metrik für die Abstandsberechnung der Nachbarn\n",
    "N_JOBS=-1 # int, default=None, -1 means using all processors.\n",
    "WEIGHTS='uniform' # weights{‘uniform’, ‘distance’} or callable, default=’uniform’\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=K_PARAM, metric=METRIC, n_jobs=N_JOBS, weights=WEIGHTS)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_predtest = classifier.predict(x_test)\n",
    "y_predtrain = classifier.predict(x_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d12d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wahrheitsmatrix und Maßzahlen der Vorhersage untersuchen\n",
    "\n",
    "# Adding classes names for better interpretation\n",
    "classes_names = ['Kein Kauf\\n(negativ)','Kauf   \\n(positiv)']\n",
    "cm = met.confusion_matrix(y_test, y_predtest);\n",
    "cmdf = pd.DataFrame(cm, columns=classes_names, index = classes_names); # data frame bilden\n",
    "tn, fp, fn, tp = cm.ravel();\n",
    "\n",
    "# Seaborn's heatmap to visualize the confusion matrix\n",
    "sns.heatmap(data=cmdf, cmap='gray_r', vmin=0, vmax=0,\n",
    "                 annot=[[f\"TN={tn:.0f}\", f\"FP={fp:.0f}\"], [f\"FN={fn:.0f}\", f\"TP={tp:.0f}\"]],\n",
    "                 linewidths=0.5, linecolor='k',  # draw black grid lines\n",
    "                 clip_on=False,                  # inhibits clipping of right and lower square lines\n",
    "                 fmt='', annot_kws={'fontsize': 16}, cbar=False, square=True);\n",
    "\n",
    "plt.title(\"Wahrheitsmatrix Testdaten (Split=\"+str(TESTANTEIL)+\", Metrik=\"+ METRIC + \" \"+str(K_PARAM)+\"-NN\");\n",
    "plt.ylabel('Aktuelle Testdaten');\n",
    "plt.xlabel('Vorhersagen');\n",
    "\n",
    "print(\"\\nHyperparameter k = \"+str(K_PARAM))\n",
    "print(\"Testdatenanteil= \"+str(TESTANTEIL))\n",
    "print(\"Abstandsmetrik = \"+str(METRIC))\n",
    "print (\"\\nTP:TN:FP:FN = \" + str (tp) +\":\" + str (tn) +\":\" + str (fp) +\":\" + str (fn) )\n",
    "print (\"Genauigkeit = {:.2f}\".format(met.accuracy_score(y_test, y_predtest)))\n",
    "print (\"Recall = {:.2f}\".format(met.recall_score(y_test, y_predtest, average='binary')))\n",
    "print (\"Präzision = {:.2f}\".format(met.precision_score(y_test, y_predtest, average='binary')))\n",
    "print (\"F1 Wert = {:.2f}\".format(met.f1_score(y_test, y_predtest, average='binary')))\n",
    "print (\"Speziftät = {:.2f}\".format(tn /(tn+fp)))\n",
    "print (\"TPR = {:.2f}\".format(tp /(tp+fp)))\n",
    "print (\"FPR = {:.2f}\".format(fp /(tn+fn)))\n",
    "print (\"TNR = {:.2f}\".format(tn /(tn+fn)))\n",
    "print (\"FNR = {:.2f}\".format(fn /(tp+fp)))\n",
    "\n",
    "print (\"\\nUmsatzsteigerung für die Testdaten = {:.2f}\".format(1.5*tn - 5.0*fn)+\" €\")\n",
    "print (\"Umsatzsteigerung für hochgerechnet für alle Daten = {:.2f}\".format((1.5*tn - 5.0*fn) * (1/TESTANTEIL) ) +\" €\")\n",
    "print (\"\\nUmsatzsteigerung für baseline (Gutschein an Alle) = {:.2f}\".format((df.shape[0] * (1-classratio) * 1.5) -\\\n",
    "                                                                           (df.shape[0] * classratio * 5)) +\" €\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9be6bf90",
   "metadata": {},
   "source": [
    "# Test für eine Vorhersage der Trainingsdaten für customernumber 36946\n",
    "# Durch Abfrage des data frame df können andere  customernumber ausgesucht werden\n",
    "\n",
    "#print (df[df['target90'] == 1])\n",
    "#print (df.loc[(df['target90'] == 1) & (df['weight'] >= 2000)])\n",
    "#filter= {\n",
    "#    'customernumber':[1,1,1],\n",
    "#    'target90':[1,1,1],\n",
    "#    'weight' :[0,1,2],\n",
    "#    'remi':[1,2,3],\n",
    "#    'w1':[1,2,3]\n",
    "#          }\n",
    "#print (pd.DataFrame(filter))\n",
    "#values=[1,2,3]\n",
    "#print(df.loc[df['weight'].isin(values)]) \n",
    "\n",
    "\n",
    "df_testx = pd.DataFrame(df.loc[[36946]]) # [[ ]], damit das locate eines einzelnen Datensatz auch eine Dataframe statt einer series zurück gibt.\n",
    "df_testx = df_testx.drop (columns=['target90'])\n",
    "target = classifier.predict(df_testx)\n",
    "print (\"Erwartert wird für customernumber 36946 target90=1, vorhergesagt wird \"+ str (target))\n",
    "print (df.filter(items = [36946], axis=0))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcb833ad",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Optimalen Hyperparameter k für k-Nearest Neighbors bestimmen\n",
    "\n",
    "acc = []\n",
    "f1s = []\n",
    "rec = []\n",
    "pre = []\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "# Berechne Maßzahlen der Vorhersagequalität für K Werte zwischen 1 and 20\n",
    "maxrange=30\n",
    "for i in range(1, maxrange):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    cm = met.confusion_matrix(y_test, y_pred)\n",
    "    tni, fpi, fni, tpi = cm.ravel()\n",
    "    tn.append(tni)\n",
    "    tp.append(tpi)\n",
    "    fn.append(fni)\n",
    "    fp.append(fpi)\n",
    "    acc.append(met.accuracy_score(y_test, y_pred))\n",
    "    rec.append(met.recall_score(y_test, y_pred, average='binary'))\n",
    "    pre.append(met.precision_score(y_test, y_pred, average='binary'))\n",
    "    f1s.append(met.f1_score(y_test, y_pred, average='binary'))\n",
    "\n",
    "figsizex=12\n",
    "figsizey=4\n",
    "plt.figure(figsize=(figsizex, figsizey))\n",
    "plt.plot(range(1, maxrange), tp, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.plot(range(1, maxrange), tn, color='green', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='green', markersize=10)\n",
    "plt.plot(range(1, maxrange), fp, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.plot(range(1, maxrange), fn, color='black', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='black', markersize=10)\n",
    "plt.title('TP (rot), TN (grün), FP (blau), FN (schwarz) gegen K Wert')\n",
    "plt.xlabel('K Wert')\n",
    "plt.ylabel('TP (rot), TN (grün), FP (blau), FN (schwarz)')\n",
    "\n",
    "plt.figure(figsize=(figsizex, figsizey))\n",
    "plt.plot(range(1, maxrange), f1s, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('F1 Score gegen K Wert')\n",
    "plt.xlabel('K Wert')\n",
    "plt.ylabel('F1 Score')\n",
    "\n",
    "plt.figure(figsize=(figsizex, figsizey))\n",
    "plt.plot(range(1, maxrange), acc, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Genauigkeit gegen K Wert')\n",
    "plt.xlabel('K Wert')\n",
    "plt.ylabel('Genauigkeit')\n",
    "\n",
    "plt.figure(figsize=(figsizex, figsizey))\n",
    "plt.plot(range(1, maxrange), rec, color='black', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='black', markersize=10)\n",
    "plt.plot(range(1, maxrange), pre, color='green', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='green', markersize=10)\n",
    "plt.title('Recall (schwarz), Präzision (grün) gegen K Wert')\n",
    "plt.xlabel('K Wert')\n",
    "plt.ylabel('Recall (schwarz), Präzision (grün)')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
